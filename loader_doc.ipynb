{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from operator import itemgetter\n",
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=3000,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "with open(\"data/hub_empreendedorismo.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data_ = [Document(page_content=d[\"page_content\"], metadata = d[\"metadata\"]) for d in data]\n",
    "data = [{\"page_content\": d[\"page_content\"].replace(\"\\n\\n\\n\", \"\\n\"), \"metadata\": d[\"metadata\"]} for d in data]\n",
    "data_ = [Document(page_content=d[\"page_content\"], metadata = d[\"metadata\"]) for d in data]\n",
    "print(len(data_))\n",
    "data_e = text_splitter.split_documents(data_)\n",
    "print(len(data_e))\n",
    "# db_emp = FAISS.from_documents(data_, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "with open(\"data\\hub_institucional.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data = [{\"page_content\": d[\"page_content\"].replace(\"\\n\\n\\n\", \"\\n\"), \"metadata\": d[\"metadata\"]} for d in data]\n",
    "data_ = [Document(page_content=d[\"page_content\"], metadata = d[\"metadata\"]) for d in data]\n",
    "print(len(data_))\n",
    "data_i = text_splitter.split_documents(data_)\n",
    "print(len(data_i))\n",
    "# db_hubi = FAISS.from_documents(data_, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 3233, which is longer than the specified 3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n",
      "301\n"
     ]
    }
   ],
   "source": [
    "with open(\"data\\hub_news.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data = [{\"page_content\": d[\"page_content\"].replace(\"\\n\\n\\n\", \"\\n\"), \"metadata\": d[\"metadata\"]} for d in data]\n",
    "data_ = [Document(page_content=d[\"page_content\"], metadata = d[\"metadata\"]) for d in data]\n",
    "print(len(data_))\n",
    "data_ = text_splitter.split_documents(data_)\n",
    "print(len(data_))\n",
    "# db_news = FAISS.from_documents(data_, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "with open(\"data\\hub_on.json\") as f:\n",
    "    data = json.load(f)\n",
    "data = [{\"page_content\": d[\"page_content\"].replace(\"\\n\\n\\n\", \"\\n\"), \"metadata\": d[\"metadata\"]} for d in data]\n",
    "data_ = [Document(page_content=d[\"page_content\"], metadata = d[\"metadata\"]) for d in data]\n",
    "print(len(data_))\n",
    "data_o = text_splitter.split_documents(data_)\n",
    "print(len(data_o))\n",
    "# db_hubo = FAISS.from_documents(data_, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "with open(\"data\\hub_rep.json\") as f:\n",
    "    data = json.load(f)\n",
    "data = [{\"page_content\": d[\"page_content\"].replace(\"\\n\\n\\n\", \"\\n\"), \"metadata\": d[\"metadata\"]} for d in data]\n",
    "data_ = [Document(page_content=d[\"page_content\"], metadata = d[\"metadata\"]) for d in data]\n",
    "print(len(data_))\n",
    "data_r = text_splitter.split_documents(data_)\n",
    "print(len(data_r))\n",
    "# db_hubr = FAISS.from_documents(data_, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "with open(\"data\\hub_social.json\") as f:\n",
    "    data = json.load(f)\n",
    "data = [{\"page_content\": d[\"page_content\"].replace(\"\\n\\n\\n\", \"\\n\"), \"metadata\": d[\"metadata\"]} for d in data]\n",
    "data_ = [Document(page_content=d[\"page_content\"], metadata = d[\"metadata\"]) for d in data]\n",
    "print(len(data_))\n",
    "data_s = text_splitter.split_documents(data_)\n",
    "print(len(data_s))\n",
    "# db_hubs = FAISS.from_documents(data_, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486\n",
      "486\n"
     ]
    }
   ],
   "source": [
    "with open(\"data\\hub_webinars.json\") as f:\n",
    "    data = json.load(f)\n",
    "data = [{\"page_content\": d[\"page_content\"].replace(\"\\n\\n\\n\", \"\\n\"), \"metadata\": d[\"metadata\"]} for d in data]\n",
    "data_ = [Document(page_content=d[\"page_content\"], metadata = d[\"metadata\"]) for d in data]\n",
    "print(len(data_))\n",
    "data_we = text_splitter.split_documents(data_)\n",
    "print(len(data_we))\n",
    "# db_hubw = FAISS.from_documents(data_, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "with open(\"data\\hub_women.json\") as f:\n",
    "    data = json.load(f)\n",
    "data = [{\"page_content\": d[\"page_content\"].replace(\"\\n\\n\\n\", \"\\n\"), \"metadata\": d[\"metadata\"]} for d in data]\n",
    "data_ = [Document(page_content=d[\"page_content\"], metadata = d[\"metadata\"]) for d in data]\n",
    "print(len(data_))\n",
    "data_w = text_splitter.split_documents(data_)\n",
    "print(len(data_w))\n",
    "# db_hubwo = FAISS.from_documents(data_, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_projects = data_w + data_o + data_r\n",
    "db_projects = FAISS.from_documents(dp_projects, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_webinars = FAISS.from_documents(data_we, embeddings)\n",
    "db_news = FAISS.from_documents(data_, embeddings)\n",
    "db_institucional = FAISS.from_documents(data_i, embeddings)\n",
    "db_empreendedorismo = FAISS.from_documents(data_e, embeddings)\n",
    "db_social = FAISS.from_documents(data_s, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_projects.save_local(\"vectorstore/hub_projects\")\n",
    "db_webinars.save_local(\"vectorstore/hub_webinars\")\n",
    "db_news.save_local(\"vectorstore/hub_news\")\n",
    "db_institucional.save_local(\"vectorstore/hub_institucional\")\n",
    "db_empreendedorismo.save_local(\"vectorstore/hub_empreendedorismo\")\n",
    "db_social.save_local(\"vectorstore/hub_social\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrievers = [db_projects, db_webinars, db_news, db_institucional, db_empreendedorismo, db_social]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrievers = [db_institucional, db_empreendedorismo, db_webinars, db_news, db_projects, db_social]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_verifier = \"\"\"\n",
    "    Voc√™ √© um agente classificador de querys. Seu trabalho √© verificar se os documentos retornados por um sistema de recupera√ß√£o de informa√ß√£o s√£o relevantes para a query feita pelo usu√°rio.\n",
    "    Para isso, voc√™ deve seguir as seguintes regras:\n",
    "\n",
    "    1. Se o documento retornado pelo sistema √© relevante, voc√™ deve retornar a mensagem \"Relevante\".\n",
    "    2. Se o documento retornado pelo sistema n√£o √© relevante, voc√™ deve retornar a mensagem \"N√£o relevante\".\n",
    "\n",
    "    Aqui est√£o os documentos retornados pelo sistema:\n",
    "    {documents}\n",
    "    A query feita pelo usu√°rio foi:\n",
    "    {query}\n",
    "\n",
    "    Responda se os documentos s√£o relevantes ou n√£o para a query.\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.02, model=\"gpt-4o-mini\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([('system', rules_verifier)])\n",
    "\n",
    "ver_agent = prompt | llm | StrOutputParser() \n",
    "\n",
    "def verifier(query, documents):\n",
    "    \n",
    "    statement = ver_agent.invoke(input={\"documents\": documents, \"query\": query})\n",
    "    return statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_agent(query, retrievers = retrievers, i = 0):\n",
    "    retriever = retrievers[i].as_retriever(search_kwargs={\"k\": 2})\n",
    "    results = retriever.invoke(query)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"Me d√™ a lista de eventos do Women in Tech.\"\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "def get_retriever(q):\n",
    "    results = ret_agent(q)\n",
    "    i=0\n",
    "    while verifier(q, results) == \"N√£o relevante\":\n",
    "        i+=1\n",
    "        if i == 6:\n",
    "            return \"N√£o h√° documentos relevantes para essa query.\"\n",
    "        results = ret_agent(q, i=i)\n",
    "        \n",
    "    return format_docs(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data de publica√ß√£o:27/08/2023\n",
      "\n",
      "Link: https://www.instagram.com/p/CwdUj0ALaUm/\n",
      "\n",
      "Venha comemorar o primeiro ano da iniciativa Women in Tech!\n",
      "\n",
      " \n",
      "\n",
      "Ser√° uma noite de comemora√ß√µes, repleta de conhecimento e troca de experi√™ncias, em que ser√£o divulgados os resultados gerados neste primeiro ano.\n",
      "\n",
      " \n",
      "\n",
      "Inscreva-se e participe!\n",
      "\n",
      " \n",
      "\n",
      "üïõ Hor√°rio: 18h30 √†s 21h30\n",
      "\n",
      "üó∫ Local: Audit√≥rio Steffi e Max Perlman - T√©rreo - Insper | Rua Quat√°, 300\n",
      "\n",
      " \n",
      "\n",
      "Veja mais informa√ß√µes e inscreva-se pelo link na bio.\n",
      "\n",
      " \n",
      "\n",
      "#SomosInsper #WomenInTech #EventosInsper #EventoMulheres #Women\n",
      "\n",
      " \n",
      "\n",
      "#PraCegoVer #PraTodosVerem Imagem com fundo na cor dourada referente ao 1¬∫ Encontro Connect & Play by Women in Tech.\n",
      "\n",
      "Data de publica√ß√£o: 29/05/2023\n",
      "\n",
      "Link: https://www.instagram.com/p/Cs0jyY_NNQW/\n",
      "\n",
      "Participe de mais uma edi√ß√£o da roda de conversa do Women in Tech!\n",
      "\n",
      " \n",
      "\n",
      "A Roda de Conversa receber√° como convidada Kamila Camilo, ativista e empreendedora social e ser√° mediada por Sthefanny Cavalcante, aluna do 3¬∫ semestre de Direito.\n",
      "\n",
      " \n",
      "\n",
      "Conhe√ßa hist√≥rias de empoderamento e representatividade, e discutir temas como carreira, vida pessoal e perspectivas para o futuro feminino.\n",
      "\n",
      " \n",
      "\n",
      "Venha conversar e refletir com outras mulheres inspiradoras.\n",
      "\n",
      "Clique no link na bio e inscreva-se!\n",
      "\n",
      " \n",
      "\n",
      "Data: 29 de maio\n",
      "\n",
      "Hor√°rio: 19h √†s 21h\n",
      "\n",
      "Local: sala 112 ‚Äì 1¬∫ andar ‚Äì Pr√©dio 2\n",
      "\n",
      "Insper - Rua Quat√°, 200\n",
      "\n",
      " \n",
      "\n",
      "#RodadeConversa #WomenInTech #EmpoderamentoFeminino #MulheresNaTecnlogia\n",
      "\n",
      " \n",
      "\n",
      "#PraCegoVer #PraTodosVerem Ilustra√ß√£o com fundo na cor bord√¥ e texto na cor branca. No texto, l√™-se \"Roda de Conversa - Women In Tech - Empoderamento, representatividade, carreira e perspectiva para o futuro feminino no mercado de trabalho\". Ao lado direito do texto, h√° fotos, cargos e nomes das palestrante.\n"
     ]
    }
   ],
   "source": [
    "print(get_retriever(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_messages = [\n",
    "        ('system', \"\"\"\n",
    "                    Voc√™ √© um assistente do Hub de inova√ß√£o do Insper. \n",
    "                    Voc√™ vai responder perguntas sobre Startups e Empreendedorismo. \n",
    "                    Se apresente e diga como voc√™ pode ajudar.\"\"\"),\n",
    "        ('system', \"Aqui est√° o contexto adicional de videos no YouYube: {all_content}\" +  \"\\n\\n\" + \\\n",
    "                    \"\"\"Sempre que poss√≠vel, cite fontes de onde voc√™ est√° tirando a informa√ß√£o de posts em redes socias e youtube. \n",
    "                    Somente cite fontes dos documentos fornecidos acima.\"\"\"),\n",
    "        ('system', \"Aqui est√° a quest√£o do usu√°rio: {user_query}\"),\n",
    "        ('system', \"Sempre responda no idioma portugu√™s\"),\n",
    "        ('system', \"Toda vez que algu√©m fizer perguntas relacionadas ao Hub voc√™ deve responder em primeira pessoa no plural usando 'Somos','Fazemos‚Äù,'criamos‚Äù,'realizamos‚Äù,'executamos'.\"),\n",
    "        ('system', \"Para todo comando inicial voc√™ deve estruturar uma resposta clara e objetiva.\"),\n",
    "        ('system', \"Use um tom mais formal e neutro, sendo objetivo e assertivo\"),\n",
    "        ('system', \"O CEMP (Centro de Empreendedorismo) √© chamado Hub de Inova√ß√£o Paulo Cunha a partir de 2023, sempre o chame assim e informe a mudan√ßa de nome quando citado\"),\n",
    "        ('system', \"O PFE (Projeto Final de Engenharia) √© chamado Capstone a partir do 2¬∫ semestre de 2024, sempre o chame assim e informe a mudan√ßa de nome quando citado.\"),\n",
    "        ('system', \"Respons√°vel pelo empreendedorismo no Hub: Thomaz Martins (Coordenador)\"),\n",
    "        ('system', \"Respons√°vel pela Comunidade do Hub: O Hub conta com uma equipe de Community managers liderada pelo David Pal√°cio\"),\n",
    "        ('system', \"\"\"O que √© o pilar de projetos de inova√ß√£o com organiza√ß√µes parceiras: \n",
    "\t                -Essa nomenclatura faz refer√™ncia a v√°rios nomes, tais como: Inova√ß√£o com organiza√ß√µes parceiras, inova√ß√£o com parceiros, inova√ß√£o com grandes empresas, projetos de inova√ß√£o, inova√ß√£o em pesquisa e desenvolvimento. \n",
    "\t                -√â o pilar onde o hub apoia empresas privadas, p√∫blicas e organiza√ß√µes de maneira geral em a√ß√µes e projetos de inova√ß√£o.\"\"\"),\n",
    "        ('system', \"Todas as empresas que apostam na inova√ß√£o e querem se conectar ao Insper podem fazer projetos de inova√ß√£o com o Hub. Existem projetos pagos, projetos com apoio de fomentos, projetos por doa√ß√£o e projetos acad√™micos gratuitos.\"),\n",
    "        ('system', \"\"\"Respons√°veis pelo pilar de projetos de inova√ß√£o com organiza√ß√µes parceiras:\n",
    "                    Rodrigo Amantea (Head)\n",
    "                    Carolina Fouad (Gerente de projetos de inova√ß√£o)\n",
    "                    Raphael Galdino (Coordenador t√©cnico)\"\"\"),\n",
    "        ('system', \"\"\"Respons√°veis pelo pilar projetos acad√™micos de Inova√ß√£o:\n",
    "                    Carolina Fouad (Gerente de projetos de inova√ß√£o)\n",
    "                    Bruna Reis Morimotto (Analista de Projetos e Inova√ß√£o)\"\"\"),\n",
    "        ('system', \"Os alunos e alumni Insper n√£o tem nenhum custo extra para usar o coworking, receber mentorias e participar do programa de acelera√ß√£o at√© o momento.\"),\n",
    "        ('system', \"Apenas para alunos, p√≥s e alumni: Todas as segundas-feiras temos sess√µes informativas para os alunos da gradua√ß√£o √†s 12h e para p√≥s e alumni √†s 18h\"),\n",
    "    ]\n",
    "    \n",
    "llm = ChatOpenAI(temperature=0.05, model=\"gpt-4o-mini-2024-07-18\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(all_messages)\n",
    "\n",
    "chatbot = {\"user_query\": RunnablePassthrough(), \"all_content\": RunnableLambda(get_retriever)} | prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N√≥s somos o Hub de Inova√ß√£o Paulo Cunha do Insper e estamos aqui para ajudar com informa√ß√µes sobre startups e empreendedorismo. \\n\\nEm rela√ß√£o aos eventos do Women in Tech, temos duas iniciativas recentes:\\n\\n1. **1¬∫ Encontro Connect & Play by Women in Tech**\\n   - **Data:** 27 de agosto de 2023\\n   - **Hor√°rio:** 18h30 √†s 21h30\\n   - **Local:** Audit√≥rio Steffi e Max Perlman - T√©rreo - Insper, Rua Quat√°, 300\\n   - **Descri√ß√£o:** Uma noite de comemora√ß√µes, repleta de conhecimento e troca de experi√™ncias, onde ser√£o divulgados os resultados gerados neste primeiro ano.\\n\\n2. **Roda de Conversa do Women in Tech**\\n   - **Data:** 29 de maio de 2023\\n   - **Hor√°rio:** 19h √†s 21h\\n   - **Local:** Sala 112 ‚Äì 1¬∫ andar ‚Äì Pr√©dio 2, Insper, Rua Quat√°, 200\\n   - **Descri√ß√£o:** A roda de conversa contar√° com a presen√ßa de Kamila Camilo, ativista e empreendedora social, mediada por Sthefanny Cavalcante, abordando temas como empoderamento e representatividade.\\n\\nSe precisar de mais informa√ß√µes ou detalhes sobre outros eventos, estamos √† disposi√ß√£o para ajudar!'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"Me d√™ a lista de eventos do Women in Tech.\"\n",
    "chatbot.invoke(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Relevante'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"O que √© o hub de Inova√ß√µes?\"\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "agent_ver = {\"query\": RunnablePassthrough(),\n",
    "             \"documents\": ret_agent | RunnableLambda(format_docs),\n",
    "             } | prompt | llm | StrOutputParser()\n",
    "\n",
    "agent_ver.invoke(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
